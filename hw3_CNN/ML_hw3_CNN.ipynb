{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_a2USyd4giE",
        "colab_type": "text"
      },
      "source": [
        "# **Homework 3 - Convolutional Neural Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMqcEj-sT1so",
        "colab_type": "text"
      },
      "source": [
        "引用套件： https://pytorch.org/docs/stable/torchvision/models.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8M1zn9Q6AL9",
        "colab_type": "text"
      },
      "source": [
        "## **goal**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp8ZhSW66Apr",
        "colab_type": "text"
      },
      "source": [
        " ----- strong baseline -----   0.79318\n",
        "\n",
        "----- simple baseline -----   0.71727\n",
        "      \n",
        "可以改的地方 (超參數)：                                                         \n",
        "        #   1. number of filters                                               \n",
        "        #   2. con_mask size\n",
        "        #   3. maxpool_size\n",
        "        #   4. convolution 次數\n",
        "        #   5. epoch 次數\n",
        "        #   6. + dropout\n",
        "        #   7. learning_rate\n",
        "        #   8. batch_size\n",
        "        #   9. 用不同的模型架構方法 (ex.resnet,....)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvKI1csW2InW",
        "colab_type": "text"
      },
      "source": [
        "# 從雲端下載我們的資料庫 (food-11)，讀者可以自行下載至本機或自己的雲端"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhzdomRTOKoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gdown --id '19CzXudqN58R3D-1G8KeFWk8UDQwlb8is' --output food-11.zip # 下載資料集\n",
        "!unzip food-11.zip # 解壓縮"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sVrKci4PUFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import 需要的套件\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import time\n",
        "from google.colab import files\n",
        "import random"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8eGzZJXEBIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 固定隨機種子\n",
        "def same_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
        "    np.random.seed(seed)  # Numpy module.\n",
        "    random.seed(seed)  # Python random module.\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "same_seeds(0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0i9ZCPrOVN_",
        "colab_type": "text"
      },
      "source": [
        "#Read image\n",
        "利用 OpenCV (cv2) 讀入照片並存放在 numpy array 中，這邊之後可以省略，我們可以直接拿取存好的 numpy 作為輸入，就不需要每次都花很多時間讀檔跟轉 numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf7QPifJQNUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readfile(path, label):\n",
        "    # label 是一個 boolean variable，代表需不需要回傳 y 值\n",
        "    image_dir = sorted(os.listdir(path)) # 把圖檔按照編號排列\n",
        "    x = np.zeros((len(image_dir), 128, 128, 3), dtype=np.uint8)\n",
        "    y = np.zeros((len(image_dir)), dtype=np.uint8)\n",
        "    for i, file in enumerate(image_dir):\n",
        "        img = cv2.imread(os.path.join(path, file))\n",
        "        x[i, :, :] = cv2.resize(img,(128, 128))\n",
        "        if label:\n",
        "          y[i] = int(file.split(\"_\")[0])\n",
        "    if label:\n",
        "      return x, y\n",
        "    else:\n",
        "      return x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ebVIY5HQQH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 分別將 training set、validation set、testing set 用 readfile 函式讀進來\n",
        "workspace_dir = './food-11'\n",
        "print(\"Reading data\")\n",
        "train_x, train_y = readfile(os.path.join(workspace_dir, \"training\"), True)\n",
        "\n",
        "# download train.npy files to local\n",
        "np.save('train_x.npy', train_x)\n",
        "np.save('train_y.npy', train_y)\n",
        "# files.download('train_x.npy')\n",
        "# files.download('train_y.npy')\n",
        "print(\"Size of training data = {}\".format(len(train_x)))\n",
        "\n",
        "# download val.npy files to local\n",
        "val_x, val_y = readfile(os.path.join(workspace_dir, \"validation\"), True)\n",
        "np.save('val_x.npy', val_x)\n",
        "np.save('val_y.npy', val_y)\n",
        "# files.download('val_x.npy')\n",
        "# files.download('val_y.npy')\n",
        "print(\"Size of validation data = {}\".format(len(val_x)))\n",
        "\n",
        "# download test.npy files to local\n",
        "test_x = readfile(os.path.join(workspace_dir, \"testing\"), False)\n",
        "np.save('test_x.npy', test_x)\n",
        "# files.download('test_x.npy')\n",
        "print(\"Size of Testing data = {}\".format(len(test_x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGn25qXI3VcG",
        "colab_type": "text"
      },
      "source": [
        "這邊可以省略以上步驟，我們直接拿把 image 存成的 nparray 拿出來讀取"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-GotdEd3UW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gdown --id '1-T3KJeY5XN94NHsdya0vH4xJX1TTQt14' --output train_x.npy \n",
        "!gdown --id '1-VRyaY86OXEsFGRJnk0A9MstsMB80V1b' --output train_y.npy \n",
        "!gdown --id '1-UK5Wjt5VSnbS4GxrTnpvDjMIdKk6znY' --output val_x.npy \n",
        "!gdown --id '1-jhA40ps45c6QfpqLK7h1QiLZeAVV4iA' --output val_y.npy \n",
        "!gdown --id '1-cKSghWRnFGnq2-tSPmnC8YwAwUfU1ik' --output test_x.npy \n",
        "train_x = np.load('train_x.npy')\n",
        "train_y = np.load('train_y.npy')\n",
        "val_x = np.load('val_x.npy')\n",
        "val_y = np.load('val_y.npy')\n",
        "test_x = np.load('test_x.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq5KVMM3OHY6",
        "colab_type": "text"
      },
      "source": [
        "# Dataset\n",
        "在 PyTorch 中，我們可以利用 torch.utils.data 的 Dataset 及 DataLoader 來\"包裝\" data，使後續的 training 及 testing 更為方便。\n",
        "\n",
        "Dataset 需要 overload 兩個函數：\\_\\_len\\_\\_ 及 \\_\\_getitem\\_\\_\n",
        "\n",
        "\\_\\_len\\_\\_ 必須要回傳 dataset 的大小，而 \\_\\_getitem\\_\\_ 則定義了當程式利用 [ ] 取值時，dataset 應該要怎麼回傳資料。\n",
        "\n",
        "實際上我們並不會直接使用到這兩個函數，但是使用 DataLoader 在 enumerate Dataset 時會使用到，沒有實做的話會在程式運行階段出現 error。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKd2abixQghI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training 時做 Data augmentation\n",
        "# 一張圖片經過旋轉、調整大小、比例尺寸，或者改變亮度色溫、翻轉等處理後，我們人眼仍能辨識出來是相同的相片，但是對機器來說那可是完全不同的新圖像了，\n",
        "# 因此， Data augmentation 就是將 dataset中既有的圖片予以修改變形，以創造出更多的圖片來讓機器學習，彌補資料量不足的困擾。\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(), # 轉成 python 圖片\n",
        "    transforms.RandomHorizontalFlip(), # 隨機將圖片水平翻轉\n",
        "    transforms.RandomRotation(15), # 隨機旋轉圖片，表示在（-15，+15）之間隨機旋轉\n",
        "    transforms.ToTensor(), # 將圖片轉成 Tensor，並把數值 normalize 到 [0,1] (data normalization) ps. Tensor 為多維張量\n",
        "    # transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5)) # 歸一化到 [-1, 1]\n",
        "])\n",
        "\n",
        "# testing 時不需做 data augmentation\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),                                    \n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "class ImgDataset(Dataset):\n",
        "    def __init__(self, x, y=None, transform=None): # transform 自己決定\n",
        "    # def __init__(self, x, y=None, transform=True): \n",
        "        self.x = x\n",
        "        # label is required to be a LongTensor\n",
        "        self.y = y\n",
        "        if y is not None:\n",
        "            self.y = torch.LongTensor(y)\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    def __getitem__(self, index):\n",
        "        X = self.x[index]\n",
        "        if self.transform is not None:\n",
        "            X = self.transform(X)\n",
        "        if self.y is not None:\n",
        "            Y = self.y[index]\n",
        "            return X, Y\n",
        "        else:\n",
        "            return X"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz6jeMnkQl0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "train_set = ImgDataset(train_x, train_y, train_transform)\n",
        "val_set = ImgDataset(val_x, val_y, test_transform)\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9YhZo7POPYG",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_SIkebWOKmZ",
        "colab_type": "text"
      },
      "source": [
        "best_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLlY7VGjJtn9",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "# best_model\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
        "        # input 維度 [3, 128, 128]\n",
        "        self.cnn = nn.Sequential(\n",
        "        # class torch.nn.Sequential(*args)\n",
        "        # 多個模塊按照它們傳入構造函數的順序被加入到神經網路中\n",
        "\n",
        "            # 讀者可以自行更改網路架構\n",
        "            # nn.Conv2d(3, 64, 3, 1, 1),  # [64, 128, 128] ps.padding 後從 128 => 130，再從 130-3+1 = 128\n",
        "            nn.Conv2d(3, 64, 5, 1, 2),  # [64, 128, 128] ps.padding 後從 128 => 132，再從 132-5+1 = 128\n",
        "            nn.BatchNorm2d(64),\n",
        "            # 2D Normalization\n",
        "            # class torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True)，\n",
        "            # 其中 num_features 為輸入的通道數，BatchNorm2d 計算的是每個通道上的歸一化特徵\n",
        "            nn.ReLU(),\n",
        "            # nn.MaxPool2d(2, 2, 0),        # [64, 64, 64] 128/2 = 64\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, 1, 1),  # [128, 128, 128] ps.padding 後從 128 => 130，再從 130-3+1 = 128\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),        # [128, 64, 64] 128/2 = 64\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32] ps.padding 後從 64 => 66，再從 66-3+1 = 64\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),        # [256, 32, 32] 64/2 = 32\n",
        "\n",
        "            nn.Conv2d(256, 512, 3, 1, 1), # [512, 32, 32] ps.padding 後從 32 => 34，再從 34-3+1 = 32\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),        # [512, 32, 32] 32/2 = 16\n",
        "            \n",
        "            nn.Conv2d(512, 512, 3, 1, 1), # [512, 16, 16] ps.padding 後從 16 => 18，再從 18-3+1 = 16\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),        # [512, 4, 4] 16/2= 8\n",
        "\n",
        "            ############################多加層數#################################\n",
        "            \n",
        "            nn.Conv2d(512, 512, 3, 1, 1), # [512, 4, 4] ps.padding 後從 8 => 10，再從 10-3+1 = 8\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),       # [512, 2, 2] 8/2= 4\n",
        "\n",
        "            nn.Conv2d(512, 512, 3, 1, 1), # [512, 4, 4] ps.padding 後從 4 => 6，再從 6-3+1 = 4\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0)        # [512, 2, 2] 4/2= 2\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            # flatten\n",
        "            nn.Linear(512*2*2, 1024),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 11)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.cnn(x)\n",
        "        out = out.view(out.size()[0], -1)\n",
        "        return self.fc(out)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuaQo467q2df",
        "colab_type": "text"
      },
      "source": [
        "half layer of best_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icGZxL-2OPJZ",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "# 這邊是負責減少一半層數的 code\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "        # class torch.nn.Sequential(*args)\n",
        "\n",
        "            nn.Conv2d(3, 64, 5, 1, 2),  # [64, 128, 128] ps.padding 後從 128 => 132，再從 132-5+1 = 128\n",
        "            # (5*5*3+1)*64 = 4,864 計算參數量\n",
        "            nn.BatchNorm2d(64),\n",
        "            # 128\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),        # [64, 64, 64] 128/2 = 64\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, 1, 1),  # [128, 128, 128] ps.padding 後從 64 => 66，再從 66-3+1 = 64\n",
        "            # (3*3*64+1)*128 = 73856\n",
        "            nn.BatchNorm2d(128),\n",
        "            # 256\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),        # [128, 64, 64] 128/2 = 64\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32] ps.padding 後從 32 => 34，再從 34-3+1 = 32\n",
        "            # (3*3*128+1)*256 = 295,168\n",
        "            nn.BatchNorm2d(256),\n",
        "            # 512\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),        # [256, 32, 32] 64/2 = 32\n",
        "\n",
        "            nn.Conv2d(256, 512, 3, 1, 1), # [512, 32, 32] ps.padding 後從 16 => 18，再從 18-3+1 = 16\n",
        "            # (3*3*256+1)*512 = 1,180,160\n",
        "            nn.BatchNorm2d(512),\n",
        "            # 1,024\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),        # [512, 32, 32] 16/2 = 8\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            # flatten\n",
        "            nn.Linear(512*8*8, 256),\n",
        "            # (512*8*8+1)*256 = 8,388,864\n",
        "            # torch.nn.Dropout(0.5),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            # (256+1)*128 = 32896\n",
        "            # torch.nn.Dropout(0.5),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 11)\n",
        "            # (128+1)*11 = 1419\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.cnn(x)\n",
        "        out = out.view(out.size()[0], -1)\n",
        "        return self.fc(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxBc6cQie8NK",
        "colab_type": "text"
      },
      "source": [
        "DNN_Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6Dzncm1e6x3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DNN\n",
        "# 沒有使用 convolution\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            # flatten\n",
        "            nn.Linear(3*128*128, 256),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            nn.BatchNorm1d(256),            \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 64),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 11),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x\n",
        "        out = out.view(out.size()[0], -1)\n",
        "        return self.fc(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDMwzD6dNSPM",
        "colab_type": "text"
      },
      "source": [
        "看一下我們使用的 model 裡面的參數資料  \n",
        "參考資料：https://www.brilliantcode.net/1646/convolutional-neural-networks-3-calculate-number-of-parameters/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co6IzOHfNQEk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Classifier().cuda()\n",
        "\n",
        "from torchsummary import summary\n",
        "summary(model, input_size=(3, 128, 128))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEnGbriXORN3",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5x-FH2Kr_jh",
        "colab_type": "text"
      },
      "source": [
        "使用 training set 訓練，並使用 validation set 尋找好的參數"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1ne9oIB-zlp",
        "colab_type": "text"
      },
      "source": [
        "epochs 介紹：   \n",
        "epochs 被定義為向前和向後傳播中所有批次的單次訓練疊代。這意味著1個周期是整個輸入數據的單次向前和向後傳遞。簡單說，epochs指的就是訓練過程中數據將被「輪」多少次，就這樣。\n",
        "\n",
        "舉個例子\n",
        "\n",
        "訓練集有1000個樣本，batchsize=10，那麼\n",
        "訓練完整個樣本集需要：100次iteration，1次epoch。   \n",
        "具體的計算公式為：   \n",
        "one epoch = numbers of iterations = N = 訓練樣本的數量/batch_size\n",
        "\n",
        "參考資料：https://kknews.cc/zh-tw/code/kban458.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHaFE-8oQtkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Classifier().cuda()\n",
        "loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # optimizer 使用 Adam\n",
        "num_epoch = 150\n",
        "best_val_acc = 0\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    epoch_start_time = time.time()\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "\n",
        "    model.train() # 確保 model 是在 train model (開啟 Dropout 等...)\n",
        "    for i, data in enumerate(train_loader):\n",
        "        optimizer.zero_grad() # 用 optimizer 將 model 參數的 gradient 歸零\n",
        "        train_pred = model(data[0].cuda()) # 利用 model 得到預測的機率分佈 這邊實際上就是去呼叫 model 的 forward 函數\n",
        "        batch_loss = loss(train_pred, data[1].cuda()) # 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\n",
        "        batch_loss.backward() # 利用 back propagation 算出每個參數的 gradient\n",
        "        optimizer.step() # 以 optimizer 用 gradient 更新參數值\n",
        "\n",
        "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
        "        train_loss += batch_loss.item()\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(val_loader):\n",
        "            val_pred = model(data[0].cuda())\n",
        "            batch_loss = loss(val_pred, data[1].cuda())\n",
        "\n",
        "            val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
        "            val_loss += batch_loss.item()\n",
        "        if(val_acc > best_val_acc):\n",
        "            best_val_acc = val_acc\n",
        "\n",
        "        #將結果 print 出來\n",
        "        print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n",
        "            (epoch + 1, num_epoch, time.time()-epoch_start_time, \\\n",
        "             train_acc/train_set.__len__(), train_loss/train_set.__len__(), val_acc/val_set.__len__(), val_loss/val_set.__len__()))\n",
        "      \n",
        "print('best_val_acc =', best_val_acc/val_set.__len__())   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEli_-lNge7B",
        "colab_type": "text"
      },
      "source": [
        "### 繪製 confusion matrix \n",
        "參考資料：  \n",
        "1. https://deeplizard.com/learn/video/0LhiS6yu2qQ   \n",
        "2. https://mathpretty.com/10675.html   \n",
        "3. https://honglung.pixnet.net/blog/post/214669413-%e6%b7%b7%e6%b7%86%e7%9f%a9%e9%99%a3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1rJEGNif4I3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    # print(cm)\n",
        "\n",
        "    plt.figure(figsize=(12, 8)) #fix_size\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEo11Cu2yo9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "prediction = []\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(val_loader):\n",
        "        val_pred = model(data[0].cuda())\n",
        "        val_label = np.argmax(val_pred.cpu().data.numpy(), axis=1)\n",
        "        for y in val_label:\n",
        "            prediction.append(y)\n",
        "target_names = [ 'Bread','Dairy product' ,'Dessert','Egg', 'Fried food', 'Meat',\n",
        "                'Noodles/Pasta', 'Rice', 'Seafood', 'Soup', 'Vegetable/Fruit']\n",
        "plt.figure(1)\n",
        "cm = confusion_matrix(val_y, prediction)\n",
        "plot_confusion_matrix(cm, classes=target_names,normalize=True,\n",
        "                    title='confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-ssSxXlsI_T",
        "colab_type": "text"
      },
      "source": [
        "得到好的參數後，我們使用 training set 和 validation set 共同訓練（資料量變多，模型效果較好）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKoUxLun8lFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "train_val_x = np.concatenate((train_x, val_x), axis=0)\n",
        "train_val_y = np.concatenate((train_y, val_y), axis=0)\n",
        "train_val_set = ImgDataset(train_val_x, train_val_y, train_transform)\n",
        "train_val_loader = DataLoader(train_val_set, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoAS5TtRsfOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.train()\n",
        "# 啟用 BatchNormalization 和 Dropout\n",
        "# model.eval()\n",
        "# 不啟用 BatchNormalization 和 Dropout\n",
        "# 訓練完 train 樣本後，生成的模型 model 要用來測試樣本。在 model(test) 之前，需要加上 model.eval()，否則的話，有輸入數據，即使不訓練，它也會改變權值。\n",
        "\n",
        "# 在做one classification的時候，訓練集和測試集的樣本分佈是不一樣的。\n",
        "model_best = Classifier().cuda()\n",
        "loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\n",
        "optimizer = torch.optim.Adam(model_best.parameters(), lr=0.001) # optimizer 使用 Adam\n",
        "num_epoch = 150\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    epoch_start_time = time.time()\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "\n",
        "    model_best.train()\n",
        "    for i, data in enumerate(train_val_loader):\n",
        "        optimizer.zero_grad()\n",
        "        train_pred = model_best(data[0].cuda())\n",
        "        batch_loss = loss(train_pred, data[1].cuda())\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
        "        train_loss += batch_loss.item()\n",
        "\n",
        "        #將結果 print 出來\n",
        "    print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f' % \\\n",
        "      (epoch + 1, num_epoch, time.time()-epoch_start_time, \\\n",
        "      train_acc/train_val_set.__len__(), train_loss/train_val_set.__len__()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMnGetD6FUEL",
        "colab_type": "text"
      },
      "source": [
        "把 train 好的 model.npy 參數存到自己的路徑"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS0P-XkhFfA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_best.eval()\n",
        "torch.save(model_best.state_dict(), 'train_model_test2_2.pkl')  # 保存整個網路\n",
        "files.download('train_model_test2_2.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o1oCMXy61_3",
        "colab_type": "text"
      },
      "source": [
        "# Testing\n",
        "利用剛剛 train 好的 model 進行 prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAR6sn8U661G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set = ImgDataset(test_x, transform=test_transform)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HznI9_-ocrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_best.eval()\n",
        "prediction = []\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(test_loader):\n",
        "        test_pred = model_best(data.cuda())\n",
        "        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n",
        "        for y in test_label:\n",
        "            prediction.append(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t2q2Th85ZUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 將結果寫入 csv 檔\n",
        "with open(\"predict.csv\", 'w') as f:\n",
        "    f.write('Id,Category\\n')\n",
        "    for i, y in  enumerate(prediction):\n",
        "        f.write('{},{}\\n'.format(i, y))\n",
        "        \n",
        "# 存到本機端\n",
        "files.download('predict.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "ML_hw3_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}