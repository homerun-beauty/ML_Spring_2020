{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_hw4_BOW.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPevzrFV5dcl",
        "colab_type": "text"
      },
      "source": [
        "# Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LAsexcU6wIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 設定路徑\n",
        "path_prefix = './'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Flw8rdFP3_oa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gdown --id '1lz0Wtwxsh5YCPdqQ3E3l_nbfJT1N13V8' --output data.zip\n",
        "!unzip data.zip\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkNZ-T4V5vBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is for filtering the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mlr2DSoN5vfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# utils.py\n",
        "# 這個block用來先定義一些等等常用到的函式\n",
        "import torch\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "\n",
        "def load_training_data(path='training_label.txt'):\n",
        "    # 把training時需要的data讀進來\n",
        "    # 如果是'training_label.txt'，需要讀取label，如果是'training_nolabel.txt'，不需要讀取label\n",
        "    if 'training_label' in path:\n",
        "        with open(path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            lines = [line.strip('\\n').split(' ') for line in lines]\n",
        "        x = [line[2:] for line in lines]\n",
        "        y = [line[0] for line in lines]\n",
        "        return x, y\n",
        "    else:\n",
        "        with open(path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            x = [line.strip('\\n').split(' ') for line in lines]\n",
        "        return x\n",
        "\n",
        "def load_testing_data(path='testing_data'):\n",
        "    # 把testing時需要的data讀進來\n",
        "    with open(path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        X = [\"\".join(line.strip('\\n').split(\",\")[1:]).strip() for line in lines[1:]]\n",
        "        X = [sen.split(' ') for sen in X]\n",
        "    return X\n",
        "\n",
        "def evaluation(outputs, labels):\n",
        "    #outputs => probability (float)\n",
        "    #labels => labels\n",
        "    outputs[outputs>=0.5] = 1 # 大於等於0.5為有惡意\n",
        "    outputs[outputs<0.5] = 0 # 小於0.5為無惡意\n",
        "    correct = torch.sum(torch.eq(outputs, labels)).item()\n",
        "    return correct"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhqkDaWu5yj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "# bow.py\n",
        "class BOW():\n",
        "    def __init__(self, max_len=10000):\n",
        "        self.wordfreq = {}\n",
        "        self.vector_size = max_len\n",
        "        self.word2idx = {}\n",
        "    def bow(self, train_sentences, test_sentences):\n",
        "        for sentence in train_sentences + test_sentences:\n",
        "            for word in sentence:\n",
        "                if word in self.wordfreq.keys(): self.wordfreq[word] += 1\n",
        "                else: self.wordfreq[word] = 1\n",
        "        self.wordfreq = sorted(self.wordfreq.items(), key=lambda x: x[1], reverse=True)\n",
        "        if self.vector_size > len(self.wordfreq): self.vector_size = len(self.wordfreq)\n",
        "        for idx, (word, freq) in enumerate(self.wordfreq):\n",
        "            if idx == self.vector_size: break\n",
        "            self.word2idx[word] = len(self.word2idx)\n",
        "        self.train_bow_list = np.zeros((len(train_sentences), self.vector_size))\n",
        "        self.test_bow_list = np.zeros((len(test_sentences), self.vector_size))\n",
        "        for idx, sentence in enumerate(train_sentences):\n",
        "            for word in sentence:\n",
        "                if word in self.word2idx.keys():\n",
        "                    self.train_bow_list[idx][self.word2idx[word]] += 1\n",
        "        for idx, sentence in enumerate(test_sentences):\n",
        "            for word in sentence:\n",
        "                if word in self.word2idx.keys():\n",
        "                    self.test_bow_list[idx][self.word2idx[word]] += 1\n",
        "    def __getitem__(self, data_type):\n",
        "        if data_type == 'train': \n",
        "            return torch.FloatTensor(self.train_bow_list)\n",
        "        elif data_type == 'test':\n",
        "            return torch.FloatTensor(self.test_bow_list)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub1d5aqY52wr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data.py\n",
        "# 實作了dataset所需要的'__init__', '__getitem__', '__len__'\n",
        "# 好讓dataloader能使用\n",
        "import torch\n",
        "from torch.utils import data\n",
        "\n",
        "class TwitterDataset(data.Dataset):\n",
        "    \"\"\"\n",
        "    Expected data shape like:(data_num, data_len)\n",
        "    Data can be a list of numpy array or a list of lists\n",
        "    input data shape : (data_num, seq_len, feature_dim)\n",
        "    \n",
        "    __len__ will return the number of data\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.label = y\n",
        "    def __getitem__(self, idx):\n",
        "        if self.label is None: return self.data[idx]\n",
        "        return self.data[idx], self.label[idx]\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhulO2dg55aK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.py\n",
        "# 這個block是要拿來訓練的模型 (sigmoid)\n",
        "import torch\n",
        "from torch import nn\n",
        "class LSTM_Net(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_layers):\n",
        "        super(LSTM_Net, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.classifier = nn.Sequential( nn.Linear(embedding_dim, 512),\n",
        "                                         nn.Linear(512, 128),\n",
        "                                         nn.Linear(128, 1),\n",
        "                                         nn.Sigmoid() )\n",
        "    def forward(self, inputs):\n",
        "        x = self.classifier(inputs.float())\n",
        "        return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tElKi-3158di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train.py\n",
        "# 這個block是用來訓練模型的\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def training(batch_size, n_epoch, lr, model_dir, train, valid, model, device):\n",
        "    total = sum(p.numel() for p in model.parameters())\n",
        "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print('\\nstart training, parameter total:{}, trainable:{}\\n'.format(total, trainable))\n",
        "    model.train() # 將model的模式設為train，這樣optimizer就可以更新model的參數\n",
        "    criterion = nn.BCELoss() # 定義損失函數，這裡我們使用binary cross entropy loss\n",
        "    t_batch = len(train) \n",
        "    v_batch = len(valid) \n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr) # 將模型的參數給optimizer，並給予適當的learning rate\n",
        "    total_loss, total_acc, best_acc = 0, 0, 0\n",
        "    for epoch in range(n_epoch):\n",
        "        total_loss, total_acc = 0, 0\n",
        "        epoch_start_time = time.time()\n",
        "        # 這段做training\n",
        "        for i, (inputs, labels) in enumerate(train):\n",
        "            inputs = inputs.to(device, dtype=torch.long) # device為\"cuda\"，將inputs轉成torch.cuda.LongTensor\n",
        "            labels = labels.to(device, dtype=torch.float) # device為\"cuda\"，將labels轉成torch.cuda.FloatTensor，因為等等要餵進criterion，所以型態要是float\n",
        "            optimizer.zero_grad() # 由於loss.backward()的gradient會累加，所以每次餵完一個batch後需要歸零\n",
        "            outputs = model(inputs) # 將input餵給模型\n",
        "            outputs = outputs.squeeze() # 去掉最外面的dimension，好讓outputs可以餵進criterion()\n",
        "            loss = criterion(outputs, labels) # 計算此時模型的training loss\n",
        "            loss.backward() # 算loss的gradient\n",
        "            optimizer.step() # 更新訓練模型的參數\n",
        "            correct = evaluation(outputs, labels) # 計算此時模型的training accuracy\n",
        "            total_acc += (correct / batch_size)\n",
        "            total_loss += loss.item()\n",
        "            print('[ Epoch{}: {}/{} ] loss:{:.3f} acc:{:.3f} '.format(\n",
        "            \tepoch+1, i+1, t_batch, loss.item(), correct*100/batch_size), end='\\r')\n",
        "        print('\\nTrain | Loss:{:.5f} Acc: {:.3f}'.format(total_loss/t_batch, total_acc/t_batch*100))\n",
        "\n",
        "        # 這段做validation\n",
        "        model.eval() # 將model的模式設為eval，這樣model的參數就會固定住\n",
        "        with torch.no_grad():\n",
        "            total_loss, total_acc = 0, 0\n",
        "            for i, (inputs, labels) in enumerate(valid):\n",
        "                inputs = inputs.to(device, dtype=torch.long) # device為\"cuda\"，將inputs轉成torch.cuda.LongTensor\n",
        "                labels = labels.to(device, dtype=torch.float) # device為\"cuda\"，將labels轉成torch.cuda.FloatTensor，因為等等要餵進criterion，所以型態要是float\n",
        "                outputs = model(inputs) # 將input餵給模型\n",
        "                outputs = outputs.squeeze() # 去掉最外面的dimension，好讓outputs可以餵進criterion()\n",
        "                loss = criterion(outputs, labels) # 計算此時模型的validation loss\n",
        "                correct = evaluation(outputs, labels) # 計算此時模型的validation accuracy\n",
        "                total_acc += (correct / batch_size)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            print(\"Valid | Loss:{:.5f} Acc: {:.3f} \".format(total_loss/v_batch, total_acc/v_batch*100))\n",
        "            if total_acc > best_acc:\n",
        "                # 如果validation的結果優於之前所有的結果，就把當下的模型存下來以備之後做預測時使用\n",
        "                best_acc = total_acc\n",
        "                #torch.save(model, \"{}/val_acc_{:.3f}.model\".format(model_dir,total_acc/v_batch*100))\n",
        "                torch.save(model, \"{}/ckpt_bow\".format(model_dir))\n",
        "                print('saving model with acc {:.3f}'.format(total_acc/v_batch*100))\n",
        "        print('epoch =', epoch, ', time cost = ', time.time()-epoch_start_time, ' sec(s)')\n",
        "        print('-----------------------------------------------')\n",
        "        model.train() # 將model的模式設為train，這樣optimizer就可以更新model的參數（因為剛剛轉成eval模式）\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voDSa3m56AE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test.py\n",
        "# 這個 block 用來對testing_data.txt做預測\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def testing(batch_size, test_loader, model, device):\n",
        "    model.eval()\n",
        "    ret_output = []\n",
        "    with torch.no_grad():\n",
        "        for i, inputs in enumerate(test_loader):\n",
        "            inputs = inputs.to(device, dtype=torch.float)\n",
        "            print(inputs)\n",
        "            # \n",
        "            outputs = model(inputs)\n",
        "            print(outputs)\n",
        "            # \n",
        "            outputs = outputs.squeeze()\n",
        "            print(outputs)\n",
        "            if(outputs[i] !=1):\n",
        "              print('dd')\n",
        "            # outputs[outputs>=0.5] = 1 # 大於等於0.5為負面\n",
        "            # outputs[outputs<0.5] = 0 # 小於0.5為正面\n",
        "            ret_output += outputs.double().tolist()\n",
        "    return ret_output"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrQ7D_5D6LMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# main.py\n",
        "import os\n",
        "import torch\n",
        "import argparse\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from gensim.models import word2vec\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 通過torch.cuda.is_available()的回傳值進行判斷是否有使用GPU的環境，如果有的話device就設為\"cuda\"，沒有的話就設為\"cpu\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 處理好各個data的路徑\n",
        "train_with_label = os.path.join(path_prefix, 'training_label.txt')\n",
        "train_no_label = os.path.join(path_prefix, 'training_nolabel.txt')\n",
        "testing_data = os.path.join(path_prefix, 'testing_data.txt')\n",
        "\n",
        "w2v_path = os.path.join(path_prefix, 'w2v_all.model') # 處理word to vec model的路徑\n",
        "\n",
        "# 定義句子長度、要不要固定embedding、batch大小、要訓練幾個epoch、learning rate的值、model的資料夾路徑\n",
        "sen_len = 30\n",
        "fix_embedding = True # fix embedding during training\n",
        "batch_size = 128\n",
        "epoch = 5\n",
        "lr = 0.001\n",
        "# model_dir = os.path.join(path_prefix, 'model/') # model directory for checkpoint model\n",
        "model_dir = path_prefix # model directory for checkpoint model\n",
        "\n",
        "print(\"loading data ...\") # 把'training_label.txt'跟'training_nolabel.txt'讀進來\n",
        "train_x, y = load_training_data(train_with_label)\n",
        "train_x_no_label = load_training_data(train_no_label)\n",
        "# test_x = load_testing_data(testing_data)\n",
        "# test_x1, test_x2\n",
        "test_x1 = [['today', 'is', 'a', 'good' ,'day', ',', 'but', 'it', 'is', 'hot'],\n",
        "           ['today', 'is', 'hot', ',', 'but', 'it', 'is', 'a', 'good', 'day']]\n",
        "# test_x2 = [['today', 'is', 'hot', ',', 'but', 'it', 'is', 'a', 'good', 'day']]\n",
        "\n",
        "# 對input跟labels做預處理\n",
        "max_len = 1200\n",
        "b_1 = BOW(max_len=max_len)\n",
        "# b_2 = BOW(max_len=max_len)\n",
        "# b.bow(train_x, test_x)\n",
        "b_1.bow(train_x, test_x1)\n",
        "train_x = b_1['train']\n",
        "# import pdb\n",
        "# pdb.set_trace()\n",
        "y = [int(label) for label in y]\n",
        "y = torch.LongTensor(y)\n",
        "\n",
        "# 製作一個model的對象(sigmid)\n",
        "model = LSTM_Net(embedding_dim=max_len, num_layers=1)\n",
        "model = model.to(device) # device為\"cuda\"，model使用GPU來訓練(餵進去的inputs也需要是cuda tensor)\n",
        "# # 製作一個model的對象(softmax)\n",
        "# model = LSTM_Net1(embedding_dim=max_len, num_layers=1)\n",
        "# model = model.to(device) # device為\"cuda\"，model使用GPU來訓練(餵進去的inputs也需要是cuda tensor)\n",
        "\n",
        "# 把data分為training data跟validation data(將一部份training data拿去當作validation data)\n",
        "X_train, X_val, y_train, y_val = train_x[1000:], train_x[:1000], y[1000:], y[:1000]\n",
        "\n",
        "# 把data做成dataset供dataloader取用\n",
        "train_dataset = TwitterDataset(X=X_train, y=y_train)\n",
        "val_dataset = TwitterDataset(X=X_val, y=y_val)\n",
        "\n",
        "# 把data 轉成 batch of tensors\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                            batch_size = batch_size,\n",
        "                                            shuffle = True,\n",
        "                                            num_workers = 8)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(dataset = val_dataset,\n",
        "                                            batch_size = batch_size,\n",
        "                                            shuffle = False,\n",
        "                                            num_workers = 8)\n",
        "\n",
        "# 開始訓練\n",
        "training(batch_size, epoch, lr, model_dir, train_loader, val_loader, model, device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQNGCB9C6NgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 開始測試模型並做預測\n",
        "print(\"loading testing data ...\")\n",
        "\n",
        "test_x1 = b_1['test']\n",
        "test_dataset = TwitterDataset(X=test_x1, y=None)\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                            batch_size = batch_size,\n",
        "                                            shuffle = False,\n",
        "                                            num_workers = 8)\n",
        "print('\\nload model ...')\n",
        "model = torch.load(os.path.join(model_dir, 'ckpt_bow'))\n",
        "outputs = testing(batch_size, test_loader, model, device)\n",
        "\n",
        "# # 寫到csv檔案供上傳kaggle\n",
        "tmp = pd.DataFrame({\"id\":[str(i) for i in range(len(test_x1))],\"label\":outputs})\n",
        "print(\"save csv ...\")\n",
        "tmp.to_csv(os.path.join(path_prefix, 'predict_bow.csv'), index=False)\n",
        "print(\"Finish Predicting\")\n",
        "\n",
        "# 以下是使用command line上傳到kaggle的方式\n",
        "# 需要先pip install kaggle、Create API Token，詳細請看https://github.com/Kaggle/kaggle-api以及https://www.kaggle.com/code1110/how-to-submit-from-google-colab\n",
        "# kaggle competitions submit [competition-name] -f [csv file path]] -m [message]\n",
        "# ex: kaggle competitions submit ml-2020spring-hw4 -f output/predict.csv -m \"......\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}