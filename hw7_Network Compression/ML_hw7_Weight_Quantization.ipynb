{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_hw7_Weight_Quantization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXMVwO8CRbqo",
        "colab_type": "text"
      },
      "source": [
        "# Homework 7 - Network Compression (Weight Quantization)\n",
        "\n",
        "> Author: Arvin Liu (b05902127@ntu.edu.tw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSroOg6n8FYc",
        "colab_type": "text"
      },
      "source": [
        "## **goal**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zSQPJdtEam2",
        "colab_type": "text"
      },
      "source": [
        " ----- strong baseline -----   0.84100\n",
        "\n",
        "----- simple baseline -----   0.83682"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Hwg2LOQRaee",
        "colab_type": "text"
      },
      "source": [
        "# Readme\n",
        "\n",
        "\n",
        "HW7的任務是模型壓縮 - Neural Network Compression。\n",
        "\n",
        "Compression有很多種門派，在這裡我們會介紹上課出現過的其中四種，分別是:\n",
        "\n",
        "* 知識蒸餾 Knowledge Distillation\n",
        "* 網路剪枝 Network Pruning\n",
        "* 用少量參數來做CNN Architecture Design\n",
        "* 參數量化 Weight Quantization\n",
        "\n",
        "在這個notebook中我們會介紹非常簡單的Weight Quantization，\n",
        "而我們有提供已經做完Knowledge Distillation的小model來做Quantization。\n",
        "\n",
        "* Model架構 / Architecute Design在同目錄中的hw7_Architecture_Design.ipynb。\n",
        "* 下載已經train好的小model(0.99M): https://drive.google.com/open?id=12wtIa0WVRcpboQzhgRUJOpcXe23tgWUL\n",
        "  * 參數為 base=16, width_mult=1 (default)\n",
        "\n",
        "\n",
        "## Weight Quantization\n",
        "<img src=\"https://i.imgur.com/SMsaiAo.png\" width=\"500px\">\n",
        "\n",
        "我們這邊會示範如何實作第一條: Using less bits to represent a value。\n",
        "\n",
        "## 好的Quantization很重要。\n",
        "這邊提供一些TA的數據供各位參考。\n",
        "\n",
        "|bit|state_dict size|accuracy|\n",
        "|-|-|-|\n",
        "|32|1047430 Bytes|0.81315|\n",
        "|16|522958 Bytes|0.81347|\n",
        "|8|268472 Bytes|0.80791|\n",
        "|7|268472 Bytes|0.80791|\n",
        "\n",
        "\n",
        "## Byte Cost\n",
        "根據[torch的官方手冊](https://pytorch.org/docs/stable/tensors.html)，我們知道torch.FloatTensor預設是32-bit，也就是佔了4byte的空間，而FloatTensor系列最低可以容忍的是16-bit。\n",
        "\n",
        "為了方便操作，我們之後會將state_dict轉成numpy array做事。\n",
        "因此我們可以先看看numpy有甚麼樣的type可以使用。(ps.)mantissa = 有效位數\n",
        "![](https://i.imgur.com/3N7tiEc.png)      \n",
        "而我們發現numpy最低有float16可以使用，因此我們可以直接靠轉型將32-bit的tensor轉換成16-bit的ndarray存起來。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUcywBAhahfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder_path = './'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDV6riQRZjzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# 固定隨機種子\n",
        "def same_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
        "    np.random.seed(seed)  # Numpy module.\n",
        "    random.seed(seed)  # Python random module.\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "same_seeds(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6PTWn7LdvMn",
        "colab_type": "text"
      },
      "source": [
        "# Read state_dict\n",
        "\n",
        "下載我們已經train好的小model的state_dict進行測試。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRe3T_Uwd29U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "ec154542-f091-4f1f-c0b2-c658a3f377f2"
      },
      "source": [
        "# !gdown --id '10usrlxc7KhTbwRTzG7IAmaFbsVdWqlQ3' --output student_custom_small.bin\n",
        "!gdown --id '1-BVZoTUkX0faW4sYk7L2qiZbo-uYdn0P' --output student_custom_small.bin\n",
        "\n",
        "import os\n",
        "import torch\n",
        "\n",
        "print(f\"\\noriginal cost: {os.stat('student_custom_small.bin').st_size} bytes.\")\n",
        "params = torch.load('student_custom_small.bin')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-BVZoTUkX0faW4sYk7L2qiZbo-uYdn0P\n",
            "To: /content/student_custom_small.bin\n",
            "\r  0% 0.00/1.05M [00:00<?, ?B/s]\r100% 1.05M/1.05M [00:00<00:00, 67.3MB/s]\n",
            "\n",
            "original cost: 1047706 bytes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXD0_G5McRGt",
        "colab_type": "text"
      },
      "source": [
        "# 32-bit Tensor -> 16-bit "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIV0BzszcQg8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f01717e-dd8a-4ef7-8346-efc49e828152"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "def encode16(params, fname):\n",
        "    '''將params壓縮成16-bit後輸出到fname。\n",
        "\n",
        "    Args:\n",
        "      params: model的state_dict。\n",
        "      fname: 壓縮後輸出的檔名。\n",
        "    '''\n",
        "\n",
        "    custom_dict = {}\n",
        "    for (name, param) in params.items():\n",
        "        param = np.float64(param.cpu().numpy())\n",
        "        # 有些東西不屬於ndarray，只是一個數字，這個時候我們就不用壓縮。\n",
        "        if type(param) == np.ndarray:\n",
        "            custom_dict[name] = np.float16(param)\n",
        "        else:\n",
        "            custom_dict[name] = param\n",
        "\n",
        "    pickle.dump(custom_dict, open(fname, 'wb'))\n",
        "\n",
        "\n",
        "def decode16(fname):\n",
        "    '''從fname讀取各個params，將其從16-bit還原回torch.tensor後存進state_dict內。\n",
        "\n",
        "    Args:\n",
        "      fname: 壓縮後的檔名。\n",
        "    '''\n",
        "\n",
        "    params = pickle.load(open(fname, 'rb'))\n",
        "    custom_dict = {}\n",
        "    for (name, param) in params.items():\n",
        "        param = torch.tensor(param)\n",
        "        custom_dict[name] = param\n",
        "\n",
        "    return custom_dict\n",
        "\n",
        "\n",
        "encode16(params, '16_bit_model.pkl')\n",
        "print(f\"16-bit cost: {os.stat('16_bit_model.pkl').st_size} bytes.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16-bit cost: 522958 bytes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mv5PtFoWgIFb",
        "colab_type": "text"
      },
      "source": [
        "# 32-bit Tensor -> 8-bit (OPTIONAL)\n",
        "\n",
        "這邊提供轉成8-bit的方法，僅供大家參考。\n",
        "因為沒有8-bit的float，所以我們先對每個weight記錄最小值和最大值，進行min-max正規化後乘上$2^8-1$在四捨五入，就可以用np.uint8存取了。\n",
        "\n",
        "$W' = round(\\frac{W - \\min(W)}{\\max(W) - \\min(W)} \\times (2^8 - 1)$)\n",
        "\n",
        "\n",
        "\n",
        "> 至於能不能轉成更低的形式，例如4-bit呢? 當然可以，待你實作。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vh9Pn-3hZEN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28ca630c-0980-4ebd-d9fc-7b26c00642a5"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "def encode8(params, fname):\n",
        "    custom_dict = {}\n",
        "    for (name, param) in params.items():\n",
        "        param = np.float64(param.cpu().numpy())\n",
        "        if type(param) == np.ndarray:\n",
        "            min_val = np.min(param)\n",
        "            max_val = np.max(param)\n",
        "            param = np.round((param - min_val) / (max_val - min_val) * 255)\n",
        "            param = np.uint8(param)\n",
        "            custom_dict[name] = (min_val, max_val, param)\n",
        "        else:\n",
        "            custom_dict[name] = param\n",
        "\n",
        "    pickle.dump(custom_dict, open(fname, 'wb'))\n",
        "\n",
        "\n",
        "def decode8(fname):\n",
        "    params = pickle.load(open(fname, 'rb'))\n",
        "    custom_dict = {}\n",
        "    for (name, param) in params.items():\n",
        "        if type(param) == tuple:\n",
        "            min_val, max_val, param = param\n",
        "            param = np.float64(param)\n",
        "            param = (param / 255 * (max_val - min_val)) + min_val\n",
        "            param = torch.tensor(param)\n",
        "        else:\n",
        "            param = torch.tensor(param)\n",
        "\n",
        "        custom_dict[name] = param\n",
        "\n",
        "    return custom_dict\n",
        "\n",
        "encode8(params, '8_bit_model.pkl')\n",
        "print(f\"8-bit cost: {os.stat('8_bit_model.pkl').st_size} bytes.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8-bit cost: 268471 bytes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1qT9UkBrRSs",
        "colab_type": "text"
      },
      "source": [
        "# testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUWeL4FmsN1-",
        "colab_type": "text"
      },
      "source": [
        "## load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjRZ93Jb5E1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 讀 train 好的檔\n",
        "# !gdown --id '10usrlxc7KhTbwRTzG7IAmaFbsVdWqlQ3' --output student_custom_small.bin #predict_0.8402332361516035_student_model.csv\n",
        "!gdown --id '1-BVZoTUkX0faW4sYk7L2qiZbo-uYdn0P' --output student_custom_small.bin #predict_0.8131195335276968student_model.csv\n",
        "\n",
        "student_net = StudentNet(base=16).cuda()\n",
        "student_net.load_state_dict(torch.load('student_custom_small.bin'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y4nEEQxqrlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# decode\n",
        "state_dicts = decode8(folder_path + '8_bit_model.pkl')\n",
        "# state_dicts = decode8('8_bit_model.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Inu3W98nwCEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "\n",
        "# Load進我們的Model架構(在hw7_Architecture_Design.ipynb內) TA_Student_Net\n",
        "!gdown --id '1lJS0ApIyi7eZ2b3GMyGxjPShI8jXM2UC' --output \"hw7_Architecture_Design.ipynb\"\n",
        "%run \"hw7_Architecture_Design.ipynb\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulukos3erQms",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "outputId": "5aafd381-4bdf-4c11-95e3-c462dd596fcd"
      },
      "source": [
        "student_net_final = StudentNet(base=16).cuda()\n",
        "student_net_final.load_state_dict(state_dicts)\n",
        "student_net_final.eval()\n",
        "\n",
        "\n",
        "# check parameters\n",
        "from torchsummary import summary\n",
        "summary(student_net_final, input_size=(3, 128, 128))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 128, 128]             448\n",
            "       BatchNorm2d-2         [-1, 16, 128, 128]              32\n",
            "             ReLU6-3         [-1, 16, 128, 128]               0\n",
            "         MaxPool2d-4           [-1, 16, 64, 64]               0\n",
            "            Conv2d-5           [-1, 16, 64, 64]             160\n",
            "       BatchNorm2d-6           [-1, 16, 64, 64]              32\n",
            "             ReLU6-7           [-1, 16, 64, 64]               0\n",
            "            Conv2d-8           [-1, 32, 64, 64]             544\n",
            "         MaxPool2d-9           [-1, 32, 32, 32]               0\n",
            "           Conv2d-10           [-1, 32, 32, 32]             320\n",
            "      BatchNorm2d-11           [-1, 32, 32, 32]              64\n",
            "            ReLU6-12           [-1, 32, 32, 32]               0\n",
            "           Conv2d-13           [-1, 64, 32, 32]           2,112\n",
            "        MaxPool2d-14           [-1, 64, 16, 16]               0\n",
            "           Conv2d-15           [-1, 64, 16, 16]             640\n",
            "      BatchNorm2d-16           [-1, 64, 16, 16]             128\n",
            "            ReLU6-17           [-1, 64, 16, 16]               0\n",
            "           Conv2d-18          [-1, 128, 16, 16]           8,320\n",
            "        MaxPool2d-19            [-1, 128, 8, 8]               0\n",
            "           Conv2d-20            [-1, 128, 8, 8]           1,280\n",
            "      BatchNorm2d-21            [-1, 128, 8, 8]             256\n",
            "            ReLU6-22            [-1, 128, 8, 8]               0\n",
            "           Conv2d-23            [-1, 256, 8, 8]          33,024\n",
            "           Conv2d-24            [-1, 256, 8, 8]           2,560\n",
            "      BatchNorm2d-25            [-1, 256, 8, 8]             512\n",
            "            ReLU6-26            [-1, 256, 8, 8]               0\n",
            "           Conv2d-27            [-1, 256, 8, 8]          65,792\n",
            "           Conv2d-28            [-1, 256, 8, 8]           2,560\n",
            "      BatchNorm2d-29            [-1, 256, 8, 8]             512\n",
            "            ReLU6-30            [-1, 256, 8, 8]               0\n",
            "           Conv2d-31            [-1, 256, 8, 8]          65,792\n",
            "           Conv2d-32            [-1, 256, 8, 8]           2,560\n",
            "      BatchNorm2d-33            [-1, 256, 8, 8]             512\n",
            "            ReLU6-34            [-1, 256, 8, 8]               0\n",
            "           Conv2d-35            [-1, 256, 8, 8]          65,792\n",
            "AdaptiveAvgPool2d-36            [-1, 256, 1, 1]               0\n",
            "           Linear-37                   [-1, 11]           2,827\n",
            "================================================================\n",
            "Total params: 256,779\n",
            "Trainable params: 256,779\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 13.13\n",
            "Params size (MB): 0.98\n",
            "Estimated Total Size (MB): 14.29\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eIbSRfXtMk5",
        "colab_type": "text"
      },
      "source": [
        "## load testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_30vu8dswQ5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import torch\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class MyDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, folderName, transform=None):\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        self.label = []\n",
        "\n",
        "        for img_path in sorted(glob(folderName + '/*.jpg')):\n",
        "            try:\n",
        "                # Get classIdx by parsing image path\n",
        "                class_idx = int(re.findall(re.compile(r'\\d+'), img_path)[1])\n",
        "            except:\n",
        "                # if inference mode (there's no answer), class_idx default 0\n",
        "                class_idx = 0\n",
        "\n",
        "            image = Image.open(img_path)\n",
        "            # Get File Descriptor\n",
        "            image_fp = image.fp\n",
        "            image.load()\n",
        "            # Close File Descriptor (or it'll reach OPEN_MAX)\n",
        "            image_fp.close()\n",
        "\n",
        "            self.data.append(image)\n",
        "            self.label.append(class_idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        image = self.data[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, self.label[idx]\n",
        "\n",
        "\n",
        "trainTransform = transforms.Compose([\n",
        "    transforms.RandomCrop(256, pad_if_needed=True, padding_mode='symmetric'),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "testTransform = transforms.Compose([\n",
        "    transforms.CenterCrop(256),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def get_dataloader(mode='training', batch_size=32):\n",
        "\n",
        "    assert mode in ['training', 'testing', 'validation']\n",
        "\n",
        "    dataset = MyDataset(\n",
        "        f'./food-11/{mode}', #原本的\n",
        "        # f'./{mode}', #之前發現 zip 沒 folder\n",
        "        transform=trainTransform if mode == 'training' else testTransform)\n",
        "    print(f'./food-11/{mode}')\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=(mode == 'training'))\n",
        "\n",
        "    return dataloader\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnryTmE23pN6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67b911e6-11ba-46ac-a772-117e44c2060c"
      },
      "source": [
        "test_dataloader = get_dataloader('testing', batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./food-11/testing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj-YKdbZ1pF-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "94d65213-738f-475f-f4e1-9080e8745ef6"
      },
      "source": [
        "import time\n",
        "SaveDirectory = os.getcwd()\n",
        "print (SaveDirectory) #Wa LA 路徑出來啦~~~"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvAzNNM-sTAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download dataset\n",
        "!gdown --id '1GzukFVznTp_RG7b2ury7hr9TwA-MyMYj' --output food-11.zip\n",
        "# Unzip the files\n",
        "!unzip food-11.zip\n",
        "\n",
        "test_dataloader = get_dataloader('testing', batch_size=32)\n",
        "print('finish test_dataloader')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTvOkgYXs0-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "student_net_final.eval()\n",
        "prediction = []\n",
        "\n",
        "# optimizer = optim.AdamW(student_net_final.parameters(), lr=1e-3)\n",
        "for now_step, batch_data in enumerate(test_dataloader):\n",
        "    # 清空 optimizer\n",
        "    # optimizer.zero_grad()\n",
        "    # 處理 input\n",
        "    inputs, hard_labels = batch_data\n",
        "    inputs = inputs.cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = student_net_final(inputs)\n",
        "        test_label = np.argmax(logits.cpu().data.numpy(), axis=1)\n",
        "        for y in test_label:\n",
        "            prediction.append(y) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59IOwNRKtD6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 丟到 hw7\n",
        "from google.colab import files\n",
        "\n",
        "#將結果寫入 csv 檔\n",
        "with open(\"predict_report1.csv\", 'w') as f:\n",
        "    f.write('Id,label\\n')\n",
        "    for i, y in  enumerate(prediction):\n",
        "        f.write('{},{}\\n'.format(i, y))\n",
        "#存到本機端\n",
        "# files.download('predict_report1.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYp-_ukItJDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 丟到 hw3\n",
        "from google.colab import files\n",
        "\n",
        "#將結果寫入 csv 檔\n",
        "with open(\"predict.csv\", 'w') as f:\n",
        "    f.write('Id,Category\\n')\n",
        "    for i, y in  enumerate(prediction):\n",
        "        f.write('{},{}\\n'.format(i, y))\n",
        "#存到本機端\n",
        "files.download('predict.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqQDnFZDwb2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "pd.read_csv(\"predict_report1.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld58-cRdceZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Kaggle Score Record\n",
        "\n",
        "# 1. predict_TA.csv\n",
        "#   acc = 0.82964\n",
        "\n",
        "# 2. predict_0.8440233236151603_student_model.csv\n",
        "#   acc = 0.04064\n",
        "#   https://drive.google.com/open?id=10uOiw6Hsn0dYQe9TnNpxGaJVp4V6QVbt\n",
        "\n",
        "# 3. predict_0.8402332361516035_student_model.csv\n",
        "#   acc = 0.86072\n",
        "#   https://drive.google.com/open?id=10usrlxc7KhTbwRTzG7IAmaFbsVdWqlQ3\n",
        "\n",
        "# 4. predict_0.8402332361516035_student_model_8bytes.csv\n",
        "#   acc = 0.85475\n",
        "#   https://drive.google.com/open?id=10usrlxc7KhTbwRTzG7IAmaFbsVdWqlQ3\n",
        "\n",
        "# 5. predict_0.8131195335276968student_model.csv\n",
        "#   acc = 0.83024\n",
        "\n",
        "# 6. predicti_8_bit_model_0.8259475218658893student_model.pkl.csv\n",
        "#   acc = 0.84578 str_best"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0M7JRXSjQwa",
        "colab_type": "text"
      },
      "source": [
        "# Q&A\n",
        "\n",
        "有任何問題Network Compression的問題可以寄信到b05902127@ntu.edu.tw。\n",
        "\n",
        "時間允許的話我會更新在這裡。"
      ]
    }
  ]
}