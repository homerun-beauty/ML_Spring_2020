{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_hw7_Architecture_Design.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8odNXcMV_wI8",
        "colab_type": "text"
      },
      "source": [
        "# Homework 7 - Network Compression (Architecuture Design)\n",
        "\n",
        "> Author: Arvin Liu (b05902127@ntu.edu.tw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YIYiHkT4CLp",
        "colab_type": "text"
      },
      "source": [
        "# Readme\n",
        "\n",
        "HW7的任務是模型壓縮 - Neural Network Compression。\n",
        "\n",
        "Compression有很多種門派，在這裡我們會介紹上課出現過的其中四種，分別是:\n",
        "\n",
        "* 知識蒸餾 Knowledge Distillation\n",
        "* 網路剪枝 Network Pruning\n",
        "* 用少量參數來做CNN Architecture Design\n",
        "* 參數量化 Weight Quantization\n",
        "\n",
        "在這個notebook中我們會介紹MobileNet v1的Architecture Design。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTz5r-Zy4UDf",
        "colab_type": "text"
      },
      "source": [
        "# Architecture Design\n",
        "\n",
        "## Depthwise & Pointwise Convolution\n",
        "![](https://i.imgur.com/FBgcA0s.png)\n",
        "> 藍色為上下層Channel的關係，綠色則為該Receptive Field的擴張。\n",
        "> (圖片引用自arxiv:1810.04231)\n",
        "\n",
        "感受野（Receptive Field）：\n",
        "在機器視覺領域的深度神經網絡中有一個概念叫做感受野，用來表示網絡內部的不同位置的神經元對原圖像的感受範圍的大小。神經元之所以無法對原始圖像的所有信息進行感知，是因為在這些網絡結構中普遍使用卷積層和pooling層，在層與層之間均為局部相連（通過sliding filter）。神經元感受野的值越大表示其能接觸到的原始圖像範圍就越大，也意味著他可能蘊含更為全局、語義層次更高的特徵；而值越小則表示其所包含的特徵越趨向於局部和細節。因此感受野的值可以大致用來判斷每一層的抽象層次。\n",
        "<img src=\"https://i.imgur.com/uIhIZ22.png\" width=\"500px\">\n",
        "\n",
        "\n",
        "(a) 就是一般的Convolution Layer，所以他的Weight連接方式會跟Fully Connected一樣，只差在原本在FC是用數字相乘後相加，Convolution Layer是圖片卷積後相加。\n",
        "\n",
        "(b) DW(Depthwise Convolution Layer)你可以想像成一張feature map各自過**一個filter**處理後，再用PW(Pointwise Convolution Layer)把所有feature map的單個pixel資訊合在一起(就是1個pixel的Fully Connected Layer)。   \n",
        "參考連結：       \n",
        "https://medium.com/@chih.sheng.huang821/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-mobilenet-depthwise-separable-convolution-f1ed016b3467    \n",
        "    \n",
        "<img src=\"https://imgur.com/b9ci1YW.png\" width=\"500px\">\n",
        "\n",
        "(c) GC(Group Convolution Layer)就是把feature map分組，讓他們自己過Convolution Layer後再重新Concat起來。算是一般的Convolution和Depthwise Convolution的折衷版。**所以說，Group Convolution的Group=Input Feautures數就會是Depthwise Convolution(因為每個Channel都各自獨立)，Group=1就會是一般的Convolution(因為就等於沒有Group)。**      \n",
        "參考連結：   \n",
        "https://blog.csdn.net/hhy_csdn/article/details/80030468    \n",
        "    \n",
        "<img src=\"https://i.imgur.com/Hqhg0Q9.png\" width=\"500px\">\n",
        "\n",
        "\n",
        "## 實作細節\n",
        "```python\n",
        "# 一般的Convolution, weight大小 = in_chs * out_chs * kernel_size^2\n",
        "nn.Conv2d(in_chs, out_chs, kernel_size, stride, padding)\n",
        "\n",
        "# Group Convolution, Group數目可以自行控制，表示要分成幾群。其中in_chs和out_chs必須要可以被groups整除。(不然沒辦法分群。)\n",
        "nn.Conv2d(in_chs, out_chs, kernel_size, stride, padding, groups=groups)\n",
        "\n",
        "# Depthwise Convolution, 輸入chs=輸出chs=Groups數目, weight大小 = in_chs * kernel_size^2\n",
        "nn.Conv2d(in_chs, out_chs=in_chs, kernel_size, stride, padding, groups=in_chs)\n",
        "\n",
        "# Pointwise Convolution, 也就是1 by 1 convolution, weight大小 = in_chs * out_chs\n",
        "nn.Conv2d(in_chs, out_chs, 1)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UejH85laZNz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# 固定隨機種子\n",
        "def same_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
        "    np.random.seed(seed)  # Numpy module.\n",
        "    random.seed(seed)  # Python random module.\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "same_seeds(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRnRXK3zQzVO",
        "colab_type": "text"
      },
      "source": [
        "# Model\n",
        "\n",
        "* training的部分請參考Network Pruning、Knowledge Distillation，或直接只用Hw3的手把手即可。\n",
        "\n",
        "> 註記: 這邊把各個Block多用一層Sequential包起來是因為Network Pruning的時候抓Layer比較方便。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrBEYCCC7JQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "class StudentNet(nn.Module):\n",
        "    '''\n",
        "      在這個Net裡面，我們會使用Depthwise & Pointwise Convolution Layer來疊model。\n",
        "      你會發現，將原本的Convolution Layer換成Dw & Pw後，Accuracy通常不會降很多。\n",
        "\n",
        "      另外，取名為StudentNet是因為這個Model等會要做Knowledge Distillation。\n",
        "    '''\n",
        "\n",
        "    def __init__(self, base=16, width_mult=1):\n",
        "        '''\n",
        "          Args:\n",
        "            base: 這個model一開始的ch數量，每過一層都會*2，直到base*16為止。\n",
        "            width_mult: 為了之後的Network Pruning使用，在base*8 chs的Layer上會 * width_mult代表剪枝後的ch數量。        \n",
        "        '''\n",
        "        super(StudentNet, self).__init__()\n",
        "        multiplier = [1, 2, 4, 8, 16, 16, 16, 16]\n",
        "\n",
        "        # bandwidth: 每一層Layer所使用的ch數量\n",
        "        bandwidth = [ base * m for m in multiplier]\n",
        "\n",
        "        # 我們只Pruning第三層以後的Layer\n",
        "        for i in range(3, 7):\n",
        "            bandwidth[i] = int(bandwidth[i] * width_mult)\n",
        "\n",
        "        self.cnn = nn.Sequential(\n",
        "            # 第一層我們通常不會拆解Convolution Layer。\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(3, bandwidth[0], 3, 1, 1),\n",
        "                nn.BatchNorm2d(bandwidth[0]),\n",
        "                nn.ReLU6(),\n",
        "                nn.MaxPool2d(2, 2, 0),\n",
        "            ),\n",
        "            # 接下來每一個Sequential Block都一樣，所以我們只講一個Block\n",
        "            nn.Sequential(\n",
        "                # Depthwise Convolution\n",
        "                nn.Conv2d(bandwidth[0], bandwidth[0], 3, 1, 1, groups=bandwidth[0]),\n",
        "                # Batch Normalization\n",
        "                nn.BatchNorm2d(bandwidth[0]),\n",
        "                # ReLU6 是限制Neuron最小只會到0，最大只會到6。 MobileNet系列都是使用ReLU6。\n",
        "                # 使用ReLU6的原因是因為如果數字太大，會不好壓到float16 / or further qunatization，因此才給個限制。\n",
        "                nn.ReLU6(),\n",
        "                # Pointwise Convolution\n",
        "                nn.Conv2d(bandwidth[0], bandwidth[1], 1),\n",
        "                # 過完Pointwise Convolution不需要再做ReLU，經驗上Pointwise + ReLU效果都會變差。\n",
        "                nn.MaxPool2d(2, 2, 0),\n",
        "                # 每過完一個Block就Down Sampling\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[1], bandwidth[1], 3, 1, 1, groups=bandwidth[1]),\n",
        "                nn.BatchNorm2d(bandwidth[1]),\n",
        "                nn.ReLU6(),\n",
        "                nn.Conv2d(bandwidth[1], bandwidth[2], 1),\n",
        "                nn.MaxPool2d(2, 2, 0),\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[2], bandwidth[2], 3, 1, 1, groups=bandwidth[2]),\n",
        "                nn.BatchNorm2d(bandwidth[2]),\n",
        "                nn.ReLU6(),\n",
        "                nn.Conv2d(bandwidth[2], bandwidth[3], 1),\n",
        "                nn.MaxPool2d(2, 2, 0),\n",
        "            ),\n",
        "\n",
        "            # 到這邊為止因為圖片已經被Down Sample很多次了，所以就不做MaxPool\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[3], bandwidth[3], 3, 1, 1, groups=bandwidth[3]),\n",
        "                nn.BatchNorm2d(bandwidth[3]),\n",
        "                nn.ReLU6(),\n",
        "                nn.Conv2d(bandwidth[3], bandwidth[4], 1),\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[4], bandwidth[4], 3, 1, 1, groups=bandwidth[4]),\n",
        "                nn.BatchNorm2d(bandwidth[4]),\n",
        "                nn.ReLU6(),\n",
        "                nn.Conv2d(bandwidth[5], bandwidth[5], 1),\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[5], bandwidth[5], 3, 1, 1, groups=bandwidth[5]),\n",
        "                nn.BatchNorm2d(bandwidth[5]),\n",
        "                nn.ReLU6(),\n",
        "                nn.Conv2d(bandwidth[6], bandwidth[6], 1),\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[6], bandwidth[6], 3, 1, 1, groups=bandwidth[6]),\n",
        "                nn.BatchNorm2d(bandwidth[6]),\n",
        "                nn.ReLU6(),\n",
        "                nn.Conv2d(bandwidth[6], bandwidth[7], 1),\n",
        "            ),\n",
        "\n",
        "            # 這邊我們採用Global Average Pooling。\n",
        "            # 如果輸入圖片大小不一樣的話，就會因為Global Average Pooling壓成一樣的形狀，這樣子接下來做FC就不會對不起來。\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            # 這邊我們直接Project到11維輸出答案。\n",
        "            nn.Linear(bandwidth[7], 11),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.cnn(x)\n",
        "        out = out.view(out.size()[0], -1)\n",
        "        return self.fc(out)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ifj6FNE1adBg",
        "colab_type": "text"
      },
      "source": [
        "看 StudentNet 參數量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiEV3BNWacVh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "outputId": "82144d1b-4dd3-4e4d-93f9-1099e46c5809"
      },
      "source": [
        "model = StudentNet()\n",
        "\n",
        "from torchsummary import summary\n",
        "summary(model, input_size=(3, 128, 128))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 128, 128]             448\n",
            "       BatchNorm2d-2         [-1, 16, 128, 128]              32\n",
            "             ReLU6-3         [-1, 16, 128, 128]               0\n",
            "         MaxPool2d-4           [-1, 16, 64, 64]               0\n",
            "            Conv2d-5           [-1, 16, 64, 64]             160\n",
            "       BatchNorm2d-6           [-1, 16, 64, 64]              32\n",
            "             ReLU6-7           [-1, 16, 64, 64]               0\n",
            "            Conv2d-8           [-1, 32, 64, 64]             544\n",
            "         MaxPool2d-9           [-1, 32, 32, 32]               0\n",
            "           Conv2d-10           [-1, 32, 32, 32]             320\n",
            "      BatchNorm2d-11           [-1, 32, 32, 32]              64\n",
            "            ReLU6-12           [-1, 32, 32, 32]               0\n",
            "           Conv2d-13           [-1, 64, 32, 32]           2,112\n",
            "        MaxPool2d-14           [-1, 64, 16, 16]               0\n",
            "           Conv2d-15           [-1, 64, 16, 16]             640\n",
            "      BatchNorm2d-16           [-1, 64, 16, 16]             128\n",
            "            ReLU6-17           [-1, 64, 16, 16]               0\n",
            "           Conv2d-18          [-1, 128, 16, 16]           8,320\n",
            "        MaxPool2d-19            [-1, 128, 8, 8]               0\n",
            "           Conv2d-20            [-1, 128, 8, 8]           1,280\n",
            "      BatchNorm2d-21            [-1, 128, 8, 8]             256\n",
            "            ReLU6-22            [-1, 128, 8, 8]               0\n",
            "           Conv2d-23            [-1, 256, 8, 8]          33,024\n",
            "           Conv2d-24            [-1, 256, 8, 8]           2,560\n",
            "      BatchNorm2d-25            [-1, 256, 8, 8]             512\n",
            "            ReLU6-26            [-1, 256, 8, 8]               0\n",
            "           Conv2d-27            [-1, 256, 8, 8]          65,792\n",
            "           Conv2d-28            [-1, 256, 8, 8]           2,560\n",
            "      BatchNorm2d-29            [-1, 256, 8, 8]             512\n",
            "            ReLU6-30            [-1, 256, 8, 8]               0\n",
            "           Conv2d-31            [-1, 256, 8, 8]          65,792\n",
            "           Conv2d-32            [-1, 256, 8, 8]           2,560\n",
            "      BatchNorm2d-33            [-1, 256, 8, 8]             512\n",
            "            ReLU6-34            [-1, 256, 8, 8]               0\n",
            "           Conv2d-35            [-1, 256, 8, 8]          65,792\n",
            "AdaptiveAvgPool2d-36            [-1, 256, 1, 1]               0\n",
            "           Linear-37                   [-1, 11]           2,827\n",
            "================================================================\n",
            "Total params: 256,779\n",
            "Trainable params: 256,779\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 13.13\n",
            "Params size (MB): 0.98\n",
            "Estimated Total Size (MB): 14.29\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPTYk9w-B_yt",
        "colab_type": "text"
      },
      "source": [
        "# Q&A\n",
        "\n",
        "有任何問題Network Compression的問題可以寄信到b05902127@ntu.edu.tw。\n",
        "\n",
        "我有空的話會更新在這裡。"
      ]
    }
  ]
}